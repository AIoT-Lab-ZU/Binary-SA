{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23e822cc-c6a9-408f-bb2d-256e9b8dae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d4716d-eaa5-4cce-98e8-87eafbd08d06",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCwfeNVd-Hdc"
   },
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Bidirectional,InputLayer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6b090d-e054-4923-901c-78613761cb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e09c0b32-682b-497e-8941-d1f9487388be",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mmgDSHjo-Zud"
   },
   "outputs": [],
   "source": [
    "# Import Sentiment140 dataset\n",
    "# Update file location of Sentiment140.csv according to your working environment\n",
    "\n",
    "data_path  = \"data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "twitter_data = pd.read_csv(data_path,names=['target','id','date','flag','user','text'],\n",
    "                           encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36d6e7b4-0b85-4f06-bb72-764ccdaed2dc",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4clzU4R-_IqE"
   },
   "outputs": [],
   "source": [
    "# Create NumPy array of unprocessed input text and target \n",
    "\n",
    "X=np.array(twitter_data['text'])\n",
    "Y=np.array(twitter_data['target'])\n",
    "\n",
    "# Set Y=1 for Positive Tweets\n",
    "Y[Y==4]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60fc25f2-1c31-408c-8edc-71c88fbf1ea0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0aHJnLhyFK80",
    "outputId": "fe50abb7-0800-49fc-b7fa-bdc1599be315"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in pain. My back and sides hurt. Not to mention crying is made of fail. \n"
     ]
    }
   ],
   "source": [
    "# Visualize Dataset\n",
    "\n",
    "index = 123  # index in range [0,1599999]\n",
    "\n",
    "print(X[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53350095-b9ff-4cf7-b247-b2d7ce6a2bcd",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYbJKYT-Ggis"
   },
   "outputs": [],
   "source": [
    "# Define Preprocessing functions\n",
    "\n",
    "def tokenize(X):\n",
    "  \"\"\"\n",
    "  Tokenize the data using nltk\n",
    "  \"\"\"\n",
    "\n",
    "  treebank = nltk.tokenize.TreebankWordTokenizer()\n",
    "  X_tokenized=[treebank.tokenize(sentence) for sentence in X]  \n",
    "  return X_tokenized\n",
    "\n",
    "\n",
    "def remove_stopwords(X):\n",
    "  \"\"\"\n",
    "  Remove Stopwords using nltk\n",
    "  \"\"\"\n",
    "\n",
    "  stopwords=nltk.corpus.stopwords.words('english') + ['@']\n",
    "  X_without_stopwords = []\n",
    "\n",
    "  for sentence in X:\n",
    "\n",
    "    temp = [word for word in sentence if not word in stopwords]\n",
    "    X_without_stopwords.append(temp) \n",
    "\n",
    "  return X_without_stopwords\n",
    "\n",
    "\n",
    "def stem(X,type='porter'):\n",
    "  \"\"\"\n",
    "  Perform Stemming using nltk\n",
    "  type = 'Porter','Snowball','Lancaster'\n",
    "  \"\"\"\n",
    "  \n",
    "  if type == 'porter':\n",
    "    stemmer= nltk.stem.PorterStemmer()\n",
    "  elif type == 'snowball':\n",
    "    stemmer = nltk.stem.SnowballStemmer()\n",
    "  elif type == 'lancaster':\n",
    "    stemmer = nltk.stem.LancasterStemmer()    \n",
    "\n",
    "  \n",
    "  X_stemmed = []\n",
    "\n",
    "  for sentence in X:\n",
    "\n",
    "    temp = [stemmer.stem(word) for word in sentence]\n",
    "    X_stemmed.append(temp)\n",
    "\n",
    "  return X_stemmed \n",
    "\n",
    "\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "        \"\"\"\n",
    "        return WORDNET POS compliance to WORDENT lemmatization (a,n,r,v) \n",
    "        \"\"\"\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return 'a'\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return 'v'\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return 'n'\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return 'r'\n",
    "        else:\n",
    "            return 'n'\n",
    "\n",
    "\n",
    "def lemmatize(X):\n",
    "  \"\"\"\n",
    "  Lemmatize words using corresponding POS tag\n",
    "  \"\"\"\n",
    "\n",
    "  lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "  \n",
    "  X_pos = []\n",
    "  X_lemmatized = []\n",
    "\n",
    "  for sentence in X :\n",
    "\n",
    "    temp = nltk.pos_tag(sentence)\n",
    "    X_pos.append(temp)  \n",
    "\n",
    "  for sentence in X_pos :\n",
    "\n",
    "    temp = [ lemmatizer.lemmatize(word[0],pos=get_wordnet_pos(word[1])) for word in sentence]\n",
    "    X_lemmatized.append(temp)  \n",
    "\n",
    "  return X_lemmatized    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0bf752-0c82-47d3-974d-556d6997e22d",
   "metadata": {
    "colab_type": "text",
    "id": "hgesb5eM9dz7"
   },
   "source": [
    "# **Training on Pre-Processed data with GloVe Word Embeddings**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f524bc71-d699-43dc-b9ee-1cb91d0c0826",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vGnvHQFI9jYR"
   },
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "X_tokenized = tokenize (X)\n",
    "\n",
    "X_without_stopwords = remove_stopwords ( X_tokenized )\n",
    "\n",
    "X_lemmatized = lemmatize ( X_without_stopwords )\n",
    "\n",
    "X_clean = []\n",
    "\n",
    "for sentence in X_lemmatized:\n",
    "\n",
    "  temp = \" \".join(sentence)\n",
    "  X_clean.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3d05eb0-0ffa-42d3-8756-bfdee022d1cd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "099aSlCgdSuH",
    "outputId": "f41677a6-ff10-4b6f-cde7-fef004193127"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of distinct tokens = 836890\n"
     ]
    }
   ],
   "source": [
    "# Count total no. of distinct tokens\n",
    "\n",
    "tokenizer = Tokenizer(filters='@')\n",
    "tokenizer.fit_on_texts(X_clean)\n",
    "\n",
    "print('No. of distinct tokens = '+str(len(tokenizer.word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aca5df81-6b2b-4368-a09c-40e0cb0ef395",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KGZbksYQdSuN"
   },
   "outputs": [],
   "source": [
    "# Define Vocabulary size (no. of most frequent tokens) to consider\n",
    "\n",
    "max_vocab=50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c11cc45a-91e8-4059-b6ad-92b675e808a9",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUZATHUKdSuQ"
   },
   "outputs": [],
   "source": [
    "# Reload Twitter dataset with new Vocabulary\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_vocab,filters='@')\n",
    "tokenizer.fit_on_texts(X_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e3605a0-c96b-4acc-bce1-60869a65709a",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vRu7fr1T_b3Y"
   },
   "outputs": [],
   "source": [
    "# Vectorize input text using Vocabulary\n",
    "\n",
    "X_clean_vectorized=tokenizer.texts_to_sequences(X_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "daab597c-5710-481e-9417-785643d124cf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u7XIoIzPdSuU",
    "outputId": "08402107-f293-4e39-83fa-c68d38edf0cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of tweets = 10.061133125\n"
     ]
    }
   ],
   "source": [
    "# Count average length of tweets\n",
    "\n",
    "length=[]\n",
    "for sentence in X_clean_vectorized:\n",
    "  length.append(len(sentence))\n",
    "  \n",
    "print('Average length of tweets = '+str(np.mean(length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a67e98f-7c33-4022-aceb-579f99708893",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pDhzyLd5dSuX"
   },
   "outputs": [],
   "source": [
    "# Define Maximum input length of the Model\n",
    "\n",
    "max_length=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a38b89aa-3e70-4aaf-8171-05bfd99acbfa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xGFaD8wW_b3b",
    "outputId": "47e59f0b-de0a-46ef-8dd4-8f77d32493dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600000, 20)\n"
     ]
    }
   ],
   "source": [
    "# Pad or Trim data to defined input length\n",
    "\n",
    "X_clean_pad = keras.preprocessing.sequence.pad_sequences(X_clean_vectorized,max_length,padding='post',\n",
    "                                                         truncating='post')\n",
    "\n",
    "print(X_clean_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9031a40-1a40-410e-8983-f5664a4fef3a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "colab_type": "code",
    "id": "h7oQjX--G3IY",
    "outputId": "fe6979ae-a6c9-4335-f827-b5c027b4006f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original :\n",
      "I am in pain. My back and sides hurt. Not to mention crying is made of fail. \n",
      "\n",
      "Tokenized :\n",
      "['I', 'am', 'in', 'pain.', 'My', 'back', 'and', 'sides', 'hurt.', 'Not', 'to', 'mention', 'crying', 'is', 'made', 'of', 'fail', '.']\n",
      "\n",
      "Stopwords removed :\n",
      "['I', 'pain.', 'My', 'back', 'sides', 'hurt.', 'Not', 'mention', 'crying', 'made', 'fail', '.']\n",
      "\n",
      "POS tagged :\n",
      "[('I', 'PRP'), ('pain.', 'VBP'), ('My', 'PRP$'), ('back', 'NN'), ('sides', 'NNS'), ('hurt.', 'VBP'), ('Not', 'RB'), ('mention', 'NN'), ('crying', 'VBG'), ('made', 'VBN'), ('fail', 'NN'), ('.', '.')]\n",
      "\n",
      "Lemmatized :\n",
      "['I', 'pain.', 'My', 'back', 'side', 'hurt.', 'Not', 'mention', 'cry', 'make', 'fail', '.']\n",
      "\n",
      "Clean :\n",
      "I pain. My back side hurt. Not mention cry make fail .\n",
      "\n",
      "Vectorized :\n",
      "[2, 3428, 62, 30, 591, 4229, 146, 831, 308, 33, 426, 4]\n",
      "\n",
      "Padded :\n",
      "[   2 3428   62   30  591 4229  146  831  308   33  426    4    0    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# Visualize pre-processed data\n",
    "\n",
    "index  = 123  # index in range [0,1599999]\n",
    "\n",
    "print('\\nOriginal :')\n",
    "print(X[index])\n",
    "print('\\nTokenized :')\n",
    "print(X_tokenized[index])\n",
    "print('\\nStopwords removed :')\n",
    "print(X_without_stopwords[index])\n",
    "print('\\nPOS tagged :')\n",
    "print(nltk.pos_tag(X_without_stopwords[index]))\n",
    "print('\\nLemmatized :')\n",
    "print(X_lemmatized[index])\n",
    "print('\\nClean :')\n",
    "print(X_clean[index])\n",
    "print('\\nVectorized :')\n",
    "print(X_clean_vectorized[index])\n",
    "print('\\nPadded :')\n",
    "print(X_clean_pad[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff5f37b1-827e-4974-8abd-42e85d28177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440000, 20)\n",
      "(160000, 20)\n",
      "(1440000, 1)\n",
      "(160000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Perform train-test split\n",
    "\n",
    "np.random.seed(123)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split (X_clean_pad,Y.reshape(Y.shape[0],1),test_size=0.1)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "98f6e4e2-7157-45bb-a7df-3d8c9f3c85c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens per batch: 640\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5000  # Only consider the top 20k words\n",
    "num_tokens_per_example = 20 \n",
    "embed_dim = 32  # Embedding size for each token.\n",
    "num_heads = 2  # Number of attention heads\n",
    "ff_dim = 32  # Hidden layer size in feedforward network.\n",
    "num_experts = 10  # Number of experts used in the Switch Transformer.\n",
    "batch_size = 32  # Batch size.\n",
    "learning_rate = 0.001  # Learning rate.\n",
    "dropout_rate = 0.25  # Dropout rate.\n",
    "num_epochs = 25  # Number of epochs.\n",
    "num_tokens_per_batch = (\n",
    "    batch_size * num_tokens_per_example\n",
    ")  # Total number of tokens per batch.\n",
    "print(f\"Number of tokens per batch: {num_tokens_per_batch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5a40568b-97f7-43fd-b1fa-89c5246d043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.maxlen = maxlen\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions\n",
    "    \n",
    "    def get_config(self):\n",
    "        return super(TokenAndPositionEmbedding,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "345422e6-4835-4236-802b-8db6f7664ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feedforward_network(ff_dim, name=None):\n",
    "    return keras.Sequential(\n",
    "        [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(ff_dim)], name=name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "df538aaa-23cf-4457-a4f8-346af6b81719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_balanced_loss(router_probs, expert_mask):\n",
    "    # router_probs [tokens_per_batch, num_experts] is the probability assigned for\n",
    "    # each expert per token. expert_mask [tokens_per_batch, num_experts] contains\n",
    "    # the expert with the highest router probability in one−hot format.\n",
    "\n",
    "    num_experts = tf.shape(expert_mask)[-1]\n",
    "    # Get the fraction of tokens routed to each expert.\n",
    "    # density is a vector of length num experts that sums to 1.\n",
    "    density = tf.reduce_mean(expert_mask, axis=0)\n",
    "    # Get fraction of probability mass assigned to each expert from the router\n",
    "    # across all tokens. density_proxy is a vector of length num experts that sums to 1.\n",
    "    density_proxy = tf.reduce_mean(router_probs, axis=0)\n",
    "    # Want both vectors to have uniform allocation (1/num experts) across all\n",
    "    # num_expert elements. The two vectors will be pushed towards uniform allocation\n",
    "    # when the dot product is minimized.\n",
    "    loss = tf.reduce_mean(density_proxy * density) * tf.cast(\n",
    "        (num_experts ** 2), tf.dtypes.float32\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dc40dbee-d414-4340-bdf0-7c110dd98eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Router(layers.Layer):\n",
    "    def __init__(self, num_experts, expert_capacity):\n",
    "        self.num_experts = num_experts\n",
    "        self.route = layers.Dense(units=num_experts)\n",
    "        self.expert_capacity = expert_capacity\n",
    "        super(Router, self).__init__()\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        # inputs shape: [tokens_per_batch, embed_dim]\n",
    "        # router_logits shape: [tokens_per_batch, num_experts]\n",
    "        router_logits = self.route(inputs)\n",
    "\n",
    "        if training:\n",
    "            # Add noise for exploration across experts.\n",
    "            router_logits += tf.random.uniform(\n",
    "                shape=router_logits.shape, minval=0.9, maxval=1.1\n",
    "            )\n",
    "        # Probabilities for each token of what expert it should be sent to.\n",
    "        router_probs = keras.activations.softmax(router_logits, axis=-1)\n",
    "        # Get the top−1 expert for each token. expert_gate is the top−1 probability\n",
    "        # from the router for each token. expert_index is what expert each token\n",
    "        # is going to be routed to.\n",
    "        expert_gate, expert_index = tf.math.top_k(router_probs, k=1)\n",
    "        # expert_mask shape: [tokens_per_batch, num_experts]\n",
    "        expert_mask = tf.one_hot(expert_index, depth=self.num_experts)\n",
    "        # Compute load balancing loss.\n",
    "        aux_loss = load_balanced_loss(router_probs, expert_mask)\n",
    "        self.add_loss(aux_loss)\n",
    "        # Experts have a fixed capacity, ensure we do not exceed it. Construct\n",
    "        # the batch indices, to each expert, with position in expert make sure that\n",
    "        # not more that expert capacity examples can be routed to each expert.\n",
    "        position_in_expert = tf.cast(\n",
    "            tf.math.cumsum(expert_mask, axis=0) * expert_mask, tf.dtypes.int32\n",
    "        )\n",
    "        # Keep only tokens that fit within expert capacity.\n",
    "        expert_mask *= tf.cast(\n",
    "            tf.math.less(\n",
    "                tf.cast(position_in_expert, tf.dtypes.int32), self.expert_capacity\n",
    "            ),\n",
    "            tf.dtypes.float32,\n",
    "        )\n",
    "        expert_mask_flat = tf.reduce_sum(expert_mask, axis=-1)\n",
    "        # Mask out the experts that have overflowed the expert capacity.\n",
    "        expert_gate *= expert_mask_flat\n",
    "        # Combine expert outputs and scaling with router probability.\n",
    "        # combine_tensor shape: [tokens_per_batch, num_experts, expert_capacity]\n",
    "        combined_tensor = tf.expand_dims(\n",
    "            expert_gate\n",
    "            * expert_mask_flat\n",
    "            * tf.squeeze(tf.one_hot(expert_index, depth=self.num_experts), 1),\n",
    "            -1,\n",
    "        ) * tf.squeeze(tf.one_hot(position_in_expert, depth=self.expert_capacity), 1)\n",
    "        # Create binary dispatch_tensor [tokens_per_batch, num_experts, expert_capacity]\n",
    "        # that is 1 if the token gets routed to the corresponding expert.\n",
    "        dispatch_tensor = tf.cast(combined_tensor, tf.dtypes.float32)\n",
    "\n",
    "        return dispatch_tensor, combined_tensor\n",
    "    def get_config(self):\n",
    "        return super(Router,self).get_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4f6a7ed9-f598-4474-8424-9f719a937111",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Switch(layers.Layer):\n",
    "    def __init__(self, num_experts, embed_dim, num_tokens_per_batch, capacity_factor=1):\n",
    "        self.num_experts = num_experts\n",
    "        self.embed_dim = embed_dim\n",
    "        self.experts = [\n",
    "            create_feedforward_network(embed_dim) for _ in range(num_experts)\n",
    "        ]\n",
    "\n",
    "        self.expert_capacity = num_tokens_per_batch // self.num_experts\n",
    "        self.router = Router(self.num_experts, self.expert_capacity)\n",
    "        super(Switch, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        num_tokens_per_example = tf.shape(inputs)[1]\n",
    "\n",
    "        # inputs shape: [num_tokens_per_batch, embed_dim]\n",
    "        inputs = tf.reshape(inputs, [num_tokens_per_batch, self.embed_dim])\n",
    "        # dispatch_tensor shape: [expert_capacity, num_experts, tokens_per_batch]\n",
    "        # combine_tensor shape: [tokens_per_batch, num_experts, expert_capacity]\n",
    "        dispatch_tensor, combine_tensor = self.router(inputs)\n",
    "        # expert_inputs shape: [num_experts, expert_capacity, embed_dim]\n",
    "        expert_inputs = tf.einsum(\"ab,acd->cdb\", inputs, dispatch_tensor)\n",
    "        expert_inputs = tf.reshape(\n",
    "            expert_inputs, [self.num_experts, self.expert_capacity, self.embed_dim]\n",
    "        )\n",
    "        # Dispatch to experts\n",
    "        expert_input_list = tf.unstack(expert_inputs, axis=0)\n",
    "        expert_output_list = [\n",
    "            self.experts[idx](expert_input)\n",
    "            for idx, expert_input in enumerate(expert_input_list)\n",
    "        ]\n",
    "        # expert_outputs shape: [expert_capacity, num_experts, embed_dim]\n",
    "        expert_outputs = tf.stack(expert_output_list, axis=1)\n",
    "        # expert_outputs_combined shape: [tokens_per_batch, embed_dim]\n",
    "        expert_outputs_combined = tf.einsum(\n",
    "            \"abc,xba->xc\", expert_outputs, combine_tensor\n",
    "        )\n",
    "        # output shape: [batch_size, num_tokens_per_example, embed_dim]\n",
    "        outputs = tf.reshape(\n",
    "            expert_outputs_combined,\n",
    "            [batch_size, num_tokens_per_example, self.embed_dim],\n",
    "        )\n",
    "        return outputs\n",
    "    def get_config(self):\n",
    "        return super(Switch,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "41c8f7b6-32e5-427c-b219-cfded2f3d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ffn, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        # The ffn can be either a standard feedforward network or a switch\n",
    "        # layer with a Mixture of Experts.\n",
    "        self.ffn = ffn\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "    def get_config(self):\n",
    "        return super(TransformerBlock,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f2341bd4-c3ff-4acc-b2f4-6d81f53104fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifier():\n",
    "    switch = Switch(num_experts, embed_dim, num_tokens_per_batch)\n",
    "    transformer_block1 = TransformerBlock(ff_dim, num_heads, switch)\n",
    "    transformer_block2 = TransformerBlock(ff_dim, num_heads, switch)\n",
    "    transformer_block3 = TransformerBlock(ff_dim, num_heads, switch)\n",
    "\n",
    "    inputs = layers.Input(shape=(num_tokens_per_example,))\n",
    "    embedding_layer = TokenAndPositionEmbedding(\n",
    "        num_tokens_per_example, vocab_size, embed_dim\n",
    "    )\n",
    "    x = embedding_layer(inputs)\n",
    "    x = transformer_block1(x)\n",
    "    x = transformer_block2(x)\n",
    "    x = transformer_block3(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "    classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1d18af1b-91e3-4ee3-b42c-fab03c8557d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 20)]              0         \n",
      "_________________________________________________________________\n",
      "token_and_position_embedding (None, 20, 32)            160640    \n",
      "_________________________________________________________________\n",
      "transformer_block_13 (Transf (None, 20, 32)            29994     \n",
      "_________________________________________________________________\n",
      "transformer_block_14 (Transf (None, 20, 32)            29994     \n",
      "_________________________________________________________________\n",
      "transformer_block_15 (Transf (None, 20, 32)            29994     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_13  (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_320 (Dense)            (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_321 (Dense)            (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 208,811\n",
      "Trainable params: 208,811\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= create_classifier()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7ae0eaf8-e156-4dfd-be74-886d5fabf405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "36000/36000 [==============================] - 3741s 104ms/step - loss: 3.1264 - accuracy: 0.7686 - val_loss: 3.0861 - val_accuracy: 0.7805\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78048, saving model to models\\swtrans.ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_26_layer_call_fn, embedding_26_layer_call_and_return_conditional_losses, embedding_27_layer_call_fn, embedding_27_layer_call_and_return_conditional_losses, multi_head_attention_13_layer_call_fn while saving (showing 5 of 190). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\swtrans.ft\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\swtrans.ft\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/25\n",
      "36000/36000 [==============================] - 4965s 138ms/step - loss: 3.1205 - accuracy: 0.7810 - val_loss: 3.1033 - val_accuracy: 0.7776\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.78048\n",
      "Epoch 3/25\n",
      "36000/36000 [==============================] - 3152s 88ms/step - loss: 3.1187 - accuracy: 0.7847 - val_loss: 3.0952 - val_accuracy: 0.7839\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78048 to 0.78393, saving model to models\\swtrans.ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_26_layer_call_fn, embedding_26_layer_call_and_return_conditional_losses, embedding_27_layer_call_fn, embedding_27_layer_call_and_return_conditional_losses, multi_head_attention_13_layer_call_fn while saving (showing 5 of 190). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\swtrans.ft\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\swtrans.ft\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/25\n",
      "36000/36000 [==============================] - 4442s 123ms/step - loss: 3.1174 - accuracy: 0.7879 - val_loss: 3.1176 - val_accuracy: 0.7855\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.78393 to 0.78547, saving model to models\\swtrans.ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_26_layer_call_fn, embedding_26_layer_call_and_return_conditional_losses, embedding_27_layer_call_fn, embedding_27_layer_call_and_return_conditional_losses, multi_head_attention_13_layer_call_fn while saving (showing 5 of 190). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\swtrans.ft\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\swtrans.ft\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/25\n",
      "36000/36000 [==============================] - 4486s 125ms/step - loss: 3.1164 - accuracy: 0.7902 - val_loss: 3.1163 - val_accuracy: 0.7863\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.78547 to 0.78631, saving model to models\\swtrans.ft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as embedding_26_layer_call_fn, embedding_26_layer_call_and_return_conditional_losses, embedding_27_layer_call_fn, embedding_27_layer_call_and_return_conditional_losses, multi_head_attention_13_layer_call_fn while saving (showing 5 of 190). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\swtrans.ft\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models\\swtrans.ft\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/25\n",
      "36000/36000 [==============================] - 4446s 124ms/step - loss: 3.1155 - accuracy: 0.7922 - val_loss: 3.1104 - val_accuracy: 0.7860\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.78631\n",
      "Epoch 00006: early stopping\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from focal_loss import BinaryFocalLoss\n",
    "model.compile(optimizer = \"adam\", loss = BinaryFocalLoss(gamma=2), metrics = ['accuracy'])\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint('models/swtrans.ft', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train,Y_train,batch_size=32,epochs=25,validation_split=0.2,callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3ab2d72f-d9e8-4d23-9a38-b82907181ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "88927f3c-7d8d-4835-ba8d-d06a3bdf4df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom_objects={'BinaryFocalLoss':BinaryFocalLoss, 'TokenAndPositionEmbedding':TokenAndPositionEmbedding}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9a0f6002-8c94-41f4-ad1e-8dae0bae4263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from focal_loss import BinaryFocalLoss\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('models/swtrans.ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2d5f86f2-9ad6-4eb0-af64-4393b4019bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.784906\n",
      "Precision: 0.776457\n",
      "Recall: 0.799832\n",
      "F1 score: 0.787971\n",
      "Cohens kappa: 0.569820\n",
      "ROC AUC: 0.869522\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "yhat1 = model.predict(X_test, verbose=0)\n",
    "\n",
    "#Binary Classification\n",
    "yhat=np.where(yhat1 > 0.5, 1,0)\n",
    "\n",
    "#Mutli-class Classification\n",
    "#yhat = np.argmax(yhat, axis = 1)\n",
    "\n",
    "\n",
    "accuracy = accuracy_score( Y_test, yhat)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(Y_test, yhat)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(Y_test, yhat)\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(Y_test, yhat)\n",
    "print('F1 score: %f' % f1)\n",
    " \n",
    "# kappa\n",
    "kappa = cohen_kappa_score(Y_test, yhat)\n",
    "print('Cohens kappa: %f' % kappa)\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(Y_test, yhat1)\n",
    "print('ROC AUC: %f' % auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6d594983-4b06-45b2-810e-b81dce2b85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:        \n",
    "        label = 'NEUTRAL'\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = 'NEGATIVE'\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = 'POSITIVE'\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return 'NEGATIVE' if score < 0.5 else 'POSITIVE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bf99ba9d-ddad-4692-9c30-cf36fa8b6e6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1537 predict_step\n        return self(x, training=False)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\functional.py:414 call\n        return self._run_internal_graph(\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:68 return_outputs_and_add_losses\n        outputs, losses = fn(*args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:164 wrap_with_training_arg\n        return control_flow_util.smart_cond(\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\control_flow_util.py:105 smart_cond\n        return tf.__internal__.smart_cond.smart_cond(\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:58 smart_cond\n        return false_fn()\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:166 <lambda>\n        lambda: replace_training_and_call(False))\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:162 replace_training_and_call\n        return wrapped_call(*args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885 __call__\n        result = self._call(*args, **kwds)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:924 _call\n        results = self._stateful_fn(*args, **kwds)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3038 __call__\n        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298 _create_graph_function\n        func_graph_module.func_graph_from_py_func(\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668 wrapped_fn\n        out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:274 restored_function_body\n        return _call_concrete_function(function, inputs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:78 _call_concrete_function\n        result = function._call_flat(tensor_inputs, function._captured_inputs)  # pylint: disable=protected-access\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:121 _call_flat\n        return super(_WrapperFunction, self)._call_flat(args, captured_inputs,\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1977 _call_flat\n        flat_outputs = forward_function.call(ctx, args_with_tangents)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:619 call\n        outputs = functional_ops.partitioned_call(\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py:1221 partitioned_call\n        op = graph.create_op(op_name, args, tout, name=op_name, attrs=op_attrs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:549 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3499 create_op\n        return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3561 _create_op_internal\n        ret = Operation(\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Cannot reshape a tensor with 5120000 elements to shape [640,32] (20480 elements) for '{{node switch_13/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](layer_normalization_26/batchnorm/add_1, switch_13/Reshape/shape)' with input shapes: [8000,20,32], [2] and with input tensors computed as partial shapes: input[1] = [640,32].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [152]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m y_pred_1d \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m y_test_1d \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(Y_test)\n\u001b[1;32m----> 3\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m y_pred_1d \u001b[38;5;241m=\u001b[39m [decode_sentiment(score, include_neutral\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m score \u001b[38;5;129;01min\u001b[39;00m scores]\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1751\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1749\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1750\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m-> 1751\u001b[0m   tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1753\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:924\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    922\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 924\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    926\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    927\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3038\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3035\u001b[0m \u001b[38;5;124;03m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[39;00m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[1;32m-> 3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\u001b[38;5;241m.\u001b[39m_call_flat(\n\u001b[0;32m   3040\u001b[0m     filtered_flat_args, captured_inputs\u001b[38;5;241m=\u001b[39mgraph_function\u001b[38;5;241m.\u001b[39mcaptured_inputs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3459\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3449\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(\n\u001b[0;32m   3450\u001b[0m     status\u001b[38;5;241m=\u001b[39mag_status, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_autograph_options):\n\u001b[0;32m   3451\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3454\u001b[0m   \u001b[38;5;66;03m# and 2. there's no provided input signature\u001b[39;00m\n\u001b[0;32m   3455\u001b[0m   \u001b[38;5;66;03m# and 3. there's been a cache miss for this calling context\u001b[39;00m\n\u001b[0;32m   3456\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experimental_relax_shapes \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   3457\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_signature \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   3458\u001b[0m       call_context_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed):\n\u001b[1;32m-> 3459\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_define_function_with_shape_relaxation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3460\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_key_context\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3462\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mmissed\u001b[38;5;241m.\u001b[39madd(call_context_key)\n\u001b[0;32m   3463\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_graph_function(args, kwargs)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3381\u001b[0m, in \u001b[0;36mFunction._define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3374\u001b[0m   (relaxed_arg_specs, relaxed_kwarg_specs) \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   3375\u001b[0m       (args, kwargs), relaxed_arg_specs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3376\u001b[0m   (args, kwargs) \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[0;32m   3377\u001b[0m       (relaxed_arg_specs, relaxed_kwarg_specs),\n\u001b[0;32m   3378\u001b[0m       flat_args,\n\u001b[0;32m   3379\u001b[0m       expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 3381\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3382\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelaxed_arg_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3383\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39marg_relaxed[rank_only_cache_key] \u001b[38;5;241m=\u001b[39m graph_function\n\u001b[0;32m   3385\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (graph_function, [\n\u001b[0;32m   3386\u001b[0m     t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m nest\u001b[38;5;241m.\u001b[39mflatten((args, kwargs), expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   3387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, (ops\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[0;32m   3388\u001b[0m                       resource_variable_ops\u001b[38;5;241m.\u001b[39mBaseResourceVariable))\n\u001b[0;32m   3389\u001b[0m ])\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3293\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   3294\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3295\u001b[0m ]\n\u001b[0;32m   3296\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   3297\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3299\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3300\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3301\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3302\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3303\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3306\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3307\u001b[0m \u001b[43m        \u001b[49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverride_flat_arg_shapes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   3309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   3310\u001b[0m     function_spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   3311\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3312\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3313\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3314\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3315\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   3316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1004\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1005\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1007\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpython_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfunc_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1012\u001b[0m                                   expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668\u001b[0m, in \u001b[0;36mFunction._defun_with_scope.<locals>.wrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m default_graph\u001b[38;5;241m.\u001b[39m_variable_creator_scope(scope, priority\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    665\u001b[0m   \u001b[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[39;00m\n\u001b[0;32m    666\u001b[0m   \u001b[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001b[39;00m\n\u001b[0;32m    667\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(compile_with_xla):\n\u001b[1;32m--> 668\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mweak_wrapped_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__wrapped__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    669\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:994\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    993\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    995\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    996\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1586 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1576 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1569 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py:1537 predict_step\n        return self(x, training=False)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\functional.py:414 call\n        return self._run_internal_graph(\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\functional.py:550 _run_internal_graph\n        outputs = node.layer(*args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\base_layer.py:1037 __call__\n        outputs = call_fn(inputs, *args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:68 return_outputs_and_add_losses\n        outputs, losses = fn(*args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:164 wrap_with_training_arg\n        return control_flow_util.smart_cond(\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\control_flow_util.py:105 smart_cond\n        return tf.__internal__.smart_cond.smart_cond(\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\smart_cond.py:58 smart_cond\n        return false_fn()\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:166 <lambda>\n        lambda: replace_training_and_call(False))\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\saving\\saved_model\\utils.py:162 replace_training_and_call\n        return wrapped_call(*args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885 __call__\n        result = self._call(*args, **kwds)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:924 _call\n        results = self._stateful_fn(*args, **kwds)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3038 __call__\n        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3463 _maybe_define_function\n        graph_function = self._create_graph_function(args, kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3298 _create_graph_function\n        func_graph_module.func_graph_from_py_func(\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1007 func_graph_from_py_func\n        func_outputs = python_func(*func_args, **func_kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:668 wrapped_fn\n        out = weak_wrapped_fn().__wrapped__(*args, **kwds)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:274 restored_function_body\n        return _call_concrete_function(function, inputs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\saved_model\\function_deserialization.py:78 _call_concrete_function\n        result = function._call_flat(tensor_inputs, function._captured_inputs)  # pylint: disable=protected-access\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\saved_model\\load.py:121 _call_flat\n        return super(_WrapperFunction, self)._call_flat(args, captured_inputs,\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1977 _call_flat\n        flat_outputs = forward_function.call(ctx, args_with_tangents)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:619 call\n        outputs = functional_ops.partitioned_call(\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\functional_ops.py:1221 partitioned_call\n        op = graph.create_op(op_name, args, tout, name=op_name, attrs=op_attrs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:549 new_func\n        return func(*args, **kwargs)\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3499 create_op\n        return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:599 _create_op_internal\n        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3561 _create_op_internal\n        ret = Operation(\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2041 __init__\n        self._c_op = _create_c_op(self._graph, node_def, inputs,\n    C:\\Users\\MMM\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1883 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Cannot reshape a tensor with 5120000 elements to shape [640,32] (20480 elements) for '{{node switch_13/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](layer_normalization_26/batchnorm/add_1, switch_13/Reshape/shape)' with input shapes: [8000,20,32], [2] and with input tensors computed as partial shapes: input[1] = [640,32].\n"
     ]
    }
   ],
   "source": [
    "y_pred_1d = []\n",
    "y_test_1d = list(Y_test)\n",
    "scores = model.predict(X_test, verbose=1, batch_size=8000)\n",
    "y_pred_1d = [decode_sentiment(score, include_neutral=False) for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0ab49c-ecf1-43eb-af02-2fb3b49bf3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_1d = [decode_sentiment(score, include_neutral=False) for score in y_test_1d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16a60e-25ae-43f7-8909-66f857abf34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56926073-ded9-4e23-945f-61dc010f72bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    labels=['Negative','Positive']\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, labels, rotation=90, fontsize=22)\n",
    "    plt.yticks(tick_marks, labels, fontsize=22)\n",
    "    \n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=25)\n",
    "    plt.xlabel('Predicted label', fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0807497-69d5-4008-a990-aa22b5b3db21",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\n",
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cnf_matrix, classes=twitter_data.target.unique(), title=\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f0efa2-9e30-4265-a7f2-a8bf0cae77ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test_1d, y_pred_1d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebae5980-80ad-43b6-8d57-7e801a70a18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred_keras = model.predict(X_test).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(Y_test, y_pred_keras)\n",
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "plt.figure(1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='(Area Under the Curve = {:.3f})'.format(auc_keras))\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title ('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4241fc-f374-445f-882d-db626a46e761",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
